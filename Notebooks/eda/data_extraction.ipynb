{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import calendar\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean columns and transform columns to datetime\n",
    "\n",
    "def process_dataframe(df):\n",
    "    # Verifica si la columna 'datetime' existe en el DataFrame\n",
    "    if 'datetime' in df.columns:\n",
    "        # Convierte la columna 'datetime' a tipo datetime con zona horaria UTC\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'], utc=True)\n",
    "        \n",
    "        # Elimina la columna 'percentage' si existe\n",
    "        if 'percentage' in df.columns:\n",
    "            df = df.drop('percentage', axis=1)\n",
    "        \n",
    "        # Elimina la información de la zona horaria para que sea similar a tu ejemplo\n",
    "        df['datetime'] = df['datetime'].dt.tz_localize(None)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling the API and create Dataframes with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common parameters\n",
    "params = {\n",
    "    'time_trunc': 'hour',\n",
    "    'geo_limit': 'peninsular',\n",
    "    'geo_ids': '8741'\n",
    "}\n",
    "\n",
    "# Define the base URL\n",
    "base_url = 'https://apidatos.ree.es/es/datos/mercados/precios-mercados-tiempo-real?'\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Calculate the start date as one year before the current date\n",
    "start_date = current_datetime - timedelta(days=365)\n",
    "\n",
    "# Initialize a list to store the DataFrames of prices\n",
    "dfs_prices = []\n",
    "\n",
    "# Create a loop to fetch data month by month\n",
    "while start_date <= current_datetime:\n",
    "    # Calculate the end date for the current month\n",
    "    year = start_date.year\n",
    "    month = start_date.month\n",
    "    last_day_of_month = (start_date.replace(day=28) + timedelta(days=4)).replace(day=1) - timedelta(days=1)\n",
    "    end_date = last_day_of_month.replace(hour=23, minute=59, second=59)\n",
    "\n",
    "    # Add the dates to the parameters\n",
    "    params['start_date'] = start_date.isoformat()\n",
    "    params['end_date'] = end_date.isoformat()\n",
    "\n",
    "    # Make the HTTP request\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the price data for the current month\n",
    "    monthly_prices = data['included'][0]['attributes']['values']\n",
    "\n",
    "    # Create a DataFrame for the current month and add it to the list\n",
    "    df_month = pd.DataFrame(monthly_prices)\n",
    "    dfs_prices.append(df_month)\n",
    "\n",
    "    # Move to the next month\n",
    "    start_date = last_day_of_month + timedelta(days=1)\n",
    "\n",
    "# Concatenate all the DataFrames into one\n",
    "df_all_prices = pd.concat(dfs_prices, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_prices = process_dataframe(df_all_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_prices.to_csv('../../data/df_yearly_prices.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Monthly demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common parameters\n",
    "params = {\n",
    "    'time_trunc': 'month',\n",
    "    'geo_limit': 'peninsular',\n",
    "    'geo_ids': '8741'\n",
    "}\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Round the current date to the previous night at 00:00\n",
    "end_date = current_datetime.replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=1)\n",
    "\n",
    "# Calculate the start date as one year ago at 00:00\n",
    "start_date = end_date - timedelta(days=365)\n",
    "\n",
    "# Convert the dates to text strings in the \"00:00\" format\n",
    "start_date_str = start_date.strftime('%Y-%m-%dT%H:%M')\n",
    "end_date_str = end_date.strftime('%Y-%m-%dT%H:%M')\n",
    "\n",
    "# Define the base URL with dynamic time parameters\n",
    "base_url = f'https://apidatos.ree.es/es/datos/demanda/demanda-maxima-diaria?start_date={start_date_str}&end_date={end_date_str}'\n",
    "\n",
    "# Make the request to the API\n",
    "response = requests.get(base_url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Extract and print the data\n",
    "df_max_demand = data['included'][0]['attributes']['values']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_max_demand = pd.DataFrame(df_max_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the DataFrame\n",
    "df_max_demand = process_dataframe(df_max_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df_max_demand.to_csv('../../data/df_max_demand.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common parameters\n",
    "params = {\n",
    "    'time_trunc': 'hour',\n",
    "    'geo_limit': 'peninsular',\n",
    "    'geo_ids': '8741'\n",
    "}\n",
    "\n",
    "# Define the base URL\n",
    "base_url = 'https://apidatos.ree.es/es/datos/demanda/demanda-tiempo-real?'\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Calculate the start date as one year before the current date\n",
    "start_date = current_datetime - timedelta(days=365)\n",
    "\n",
    "# Initialize a list to store the DataFrames of prices\n",
    "dfs_demand = {}\n",
    "\n",
    "# Create a loop to fetch data month by month\n",
    "while start_date <= current_datetime:\n",
    "    # Calculate the end date for the current month\n",
    "    year = start_date.year\n",
    "    month = start_date.month\n",
    "    last_day_of_month = (start_date.replace(day=28) + timedelta(days=4)).replace(day=1) - timedelta(days=1)\n",
    "    end_date = last_day_of_month.replace(hour=23, minute=59, second=59)\n",
    "\n",
    "    # Add the dates to the parameters\n",
    "    params['start_date'] = start_date.isoformat()\n",
    "    params['end_date'] = end_date.isoformat()\n",
    "\n",
    "    # Make the HTTP request\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the price data for the current month\n",
    "    monthly_demand_1 = data['included'][0]['attributes']['values']\n",
    "    monthly_demand_2 = data['included'][1]['attributes']['values']\n",
    "    monthly_demand_3 = data['included'][2]['attributes']['values']\n",
    "    type_name_1 = data['included'][0]['type']\n",
    "    type_name_2 = data['included'][1]['type']\n",
    "    type_name_3 = data['included'][2]['type']\n",
    "\n",
    "\n",
    "    # Create a DataFrame for the current month\n",
    "    df_month_1 = pd.DataFrame(monthly_demand_1)\n",
    "    df_month_2 = pd.DataFrame(monthly_demand_2)\n",
    "    df_month_3 = pd.DataFrame(monthly_demand_3)\n",
    "\n",
    "    # Move to the next month\n",
    "    start_date = last_day_of_month + timedelta(days=1)\n",
    "\n",
    "# Add the DataFrames to the dictionary\n",
    "dfs_demand['Real'] = df_month_1\n",
    "dfs_demand['Prevista'] = df_month_2\n",
    "dfs_demand['Programada'] = df_month_3\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the DataFrames\n",
    "dfs_demand['Real'] = process_dataframe(dfs_demand['Real'])\n",
    "dfs_demand['Prevista'] = process_dataframe(dfs_demand['Prevista'])\n",
    "dfs_demand['Programada'] = process_dataframe(dfs_demand['Programada'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrames to CSV\n",
    "dfs_demand['Real'].to_csv('../../data/df_real_demand.csv', index=False)\n",
    "dfs_demand['Prevista'].to_csv('../../data/df_expected_demand.csv', index=False)\n",
    "dfs_demand['Programada'].to_csv('../../data/df_programed_demand.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common parameters\n",
    "params = {\n",
    "    'time_trunc': 'day',\n",
    "    'geo_limit': 'peninsular',\n",
    "    'geo_ids': '8741'\n",
    "}\n",
    "\n",
    "# Define the base URL\n",
    "base_url = 'https://apidatos.ree.es/es/datos/generacion/estructura-generacion?'\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Calculate the start date as one year before the current date\n",
    "params['start_date'] = current_datetime - timedelta(days=365)\n",
    "\n",
    "# Calculate the end date as the current date\n",
    "params['end_date'] = current_datetime\n",
    "\n",
    "# Initialize a dictionary to store DataFrames for each 'type'\n",
    "dfs_structure_by_type = {}\n",
    "\n",
    "# Make the initial HTTP request and store the data\n",
    "response = requests.get(base_url, params=params)\n",
    "data = response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the 'included' list and store the DataFrames\n",
    "for i in range(len(data['included'])):\n",
    "    type_name = data['included'][i]['type']\n",
    "    dfs_structure_by_type[type_name] = pd.DataFrame(data['included'][i]['attributes']['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the consolidated data\n",
    "consolidated_df = pd.DataFrame(columns=['values', 'percentage', 'datetime',])\n",
    "for key, df in dfs_structure_by_type.items():\n",
    "    # Renombra las columnas 'values' y 'datetime' para que tengan el nombre del tipo de generación\n",
    "    \n",
    "    # Fusiona el DataFrame actual con el consolidado en función de la columna 'datetime'\n",
    "    consolidated_df = pd.merge(consolidated_df, df, on='datetime', how='outer')\n",
    "\n",
    "# drop all the columns that contains 'percentage'\n",
    "df_structure_merge = consolidated_df.loc[:,~consolidated_df.columns.str.contains('percentage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_structure_merge = process_dataframe(df_structure_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are not needed\n",
    "df_structure_merge = df_structure_merge.iloc[:, [i for i in range(df_structure_merge.shape[1]) if i not in [0, 6]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrames to CSV\n",
    "df_structure_merge.to_csv('../../data/df_structure_merge.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installed power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common parameters\n",
    "params = {\n",
    "    'time_trunc': 'day',\n",
    "    'geo_limit': 'peninsular',\n",
    "    'geo_ids': '8741'\n",
    "}\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Round the current date to the previous night at 00:00\n",
    "end_date = current_datetime.replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=1)\n",
    "\n",
    "# Calculate the start date as one year ago at 00:00\n",
    "start_date = end_date - timedelta(days=365)\n",
    "\n",
    "# Convert the dates to text strings in the \"00:00\" format\n",
    "start_date_str = start_date.strftime('%Y-%m-%dT%H:%M')\n",
    "end_date_str = end_date.strftime('%Y-%m-%dT%H:%M')\n",
    "\n",
    "# Define the base URL with dynamic time parameters\n",
    "base_url = f'https://apidatos.ree.es/es/datos/generacion/potencia-instalada?start_date={start_date_str}&end_date={end_date_str}'\n",
    "\n",
    "# Make the request to the API\n",
    "response = requests.get(base_url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# create dataframe for each type\n",
    "dfs_power_by_type = {}\n",
    "\n",
    "for i in range(len(data['included'])):\n",
    "    type_name = data['included'][i]['type']\n",
    "\n",
    "    # Initialize a DataFrame for the current type with the name as the key\n",
    "    dfs_power_by_type[type_name] = pd.DataFrame()\n",
    "\n",
    "    # Extract the 'values' data\n",
    "    values = data['included'][i]['attributes']['values']\n",
    "\n",
    "    # Create a DataFrame for the current month\n",
    "    df_month = pd.DataFrame(values)\n",
    "\n",
    "    # Concatenate the current month's data with the type's DataFrame\n",
    "    dfs_power_by_type[type_name] = pd.concat([dfs_power_by_type[type_name], df_month], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the consolidated data\n",
    "consolidated_df1 = pd.DataFrame(columns=['values', 'percentage', 'datetime',])\n",
    "for key, df in dfs_power_by_type.items():\n",
    "    # Renombra las columnas 'values' y 'datetime' para que tengan el nombre del tipo de generación\n",
    "    \n",
    "    # Fusiona el DataFrame actual con el consolidado en función de la columna 'datetime'\n",
    "    consolidated_df1 = pd.merge(consolidated_df1, df, on='datetime', how='outer')\n",
    "\n",
    "\n",
    "df_power_merge = consolidated_df1.loc[:,~consolidated_df1.columns.str.contains('percentage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrames to CSV\n",
    "df_power_merge.to_csv('../../data/df_power_merge.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common parameters\n",
    "params = {\n",
    "    'time_trunc': 'day',\n",
    "    'geo_limit': 'peninsular',\n",
    "    'geo_ids': '8741'\n",
    "}\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Round the current date to the previous night at 00:00\n",
    "end_date = current_datetime.replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=1)\n",
    "\n",
    "# Calculate the start date as one year ago at 00:00\n",
    "start_date = end_date - timedelta(days=365)\n",
    "\n",
    "# Convert the dates to text strings in the \"00:00\" format\n",
    "start_date_str = start_date.strftime('%Y-%m-%dT%H:%M')\n",
    "end_date_str = end_date.strftime('%Y-%m-%dT%H:%M')\n",
    "\n",
    "# Define the base URL with dynamic time parameters\n",
    "base_url = f'https://apidatos.ree.es/es/datos/intercambios/todas-fronteras-programados?start_date={start_date_str}&end_date={end_date_str}'\n",
    "\n",
    "# Make the request to the API\n",
    "response = requests.get(base_url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "dfs_exchange_by_country = {}\n",
    "\n",
    "for i in range(len(data['included']) -1):\n",
    "    type_name = data['included'][i]['type']\n",
    "\n",
    "    # Initialize a DataFrame for the current type with the name as the key\n",
    "    dfs_exchange_by_country[type_name] = pd.DataFrame()\n",
    "\n",
    "    # Extract the 'values' data\n",
    "    values = data['included'][i]['attributes']['content'][2]['attributes']['values']\n",
    "\n",
    "    # Create a DataFrame for the current month\n",
    "    df_month = pd.DataFrame(values)\n",
    "\n",
    "    # Concatenate the current month's data with the type's DataFrame\n",
    "    dfs_exchange_by_country[type_name] = pd.concat([dfs_exchange_by_country[type_name], df_month], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the consolidated data\n",
    "consolidates_df2 = pd.DataFrame(columns=['values', 'percentage', 'datetime',])\n",
    "for key, df in dfs_exchange_by_country.items():\n",
    "    # Renombra las columnas 'values' y 'datetime' para que tengan el nombre del tipo de generación\n",
    "    \n",
    "    # Fusiona el DataFrame actual con el consolidado en función de la columna 'datetime'\n",
    "    consolidates_df2 = pd.merge(consolidates_df2, df, on='datetime', how='outer')\n",
    "\n",
    "\n",
    "# drop all the columns that contains 'percentage'\n",
    "df_exchange_merge = consolidates_df2.loc[:,~consolidates_df2.columns.str.contains('percentage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrames to CSV\n",
    "df_exchange_merge.to_csv('../../data/df_exchange_merge.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy price components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common parameters\n",
    "params = {\n",
    "    'time_trunc': 'month',\n",
    "    'geo_limit': 'peninsular',\n",
    "    'geo_ids': '8741'\n",
    "}\n",
    "\n",
    "# Define the base URL\n",
    "base_url = 'https://apidatos.ree.es/es/datos/mercados/componentes-precio-energia-cierre-desglose?'\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Round the current date to the previous night at 00:00\n",
    "end_date = current_datetime.replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=1)\n",
    "\n",
    "# Calculate the start date as one year ago at 00:00\n",
    "start_date = end_date - timedelta(days=365)\n",
    "\n",
    "# Convert the dates to text strings in the \"00:00\" format\n",
    "start_date_str = start_date.strftime('%Y-%m-%dT%H:%M')\n",
    "end_date_str = end_date.strftime('%Y-%m-%dT%H:%M')\n",
    "\n",
    "params['start_date'] = start_date_str\n",
    "params['end_date'] = end_date_str\n",
    "\n",
    "# Create dictionary to store dataframes\n",
    "dfs_components_daily = {}\n",
    "dfs_components_intradaily = {}\n",
    "\n",
    "\n",
    "# Make the request to the API\n",
    "response = requests.get(base_url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Extract and print the data\n",
    "for i in range(len(data['included'])):\n",
    "    type_name = data['included'][i]['type']\n",
    "\n",
    "    # Initialize a DataFrame for the current type with the name as the key\n",
    "    dfs_components_daily[type_name] = pd.DataFrame()\n",
    "\n",
    "    # Extract the 'values' data\n",
    "    values = data['included'][i]['attributes']['content'][0]['attributes']['values']\n",
    "\n",
    "\n",
    "    # Create a DataFrame for the current month\n",
    "    df_month = pd.DataFrame(values)\n",
    "\n",
    "    # Concatenate the current month's data with the type's DataFrame']\n",
    "    dfs_components_daily[type_name] = pd.concat([dfs_components_daily[type_name], df_month], ignore_index=True)\n",
    "\n",
    "# Extract and print the data\n",
    "for i in range(len(data['included']) - 2):\n",
    "    type_name = data['included'][i]['type']\n",
    "\n",
    "    # Initialize a DataFrame for the current type with the name as the key\n",
    "    dfs_components_intradaily[type_name] = pd.DataFrame()\n",
    "\n",
    "    # Extract the 'values' data\n",
    "    values2 = data['included'][i]['attributes']['content'][1]['attributes']['values']\n",
    "\n",
    "\n",
    "    # Create a DataFrame for the current month\n",
    "    df_month2 = pd.DataFrame(values2)\n",
    "\n",
    "    # Concatenate the current month's data with the type's DataFrame']\n",
    "    dfs_components_intradaily[type_name] = pd.concat([dfs_components_intradaily[type_name], df_month2], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the consolidated data\n",
    "consolidated_df3 = pd.DataFrame(columns=['values', 'percentage', 'datetime',])\n",
    "for key, df in dfs_components_daily.items():\n",
    "    # Renombra las columnas 'values' y 'datetime' para que tengan el nombre del tipo de generación\n",
    "    \n",
    "    # Fusiona el DataFrame actual con el consolidado en función de la columna 'datetime'\n",
    "    consolidated_df3 = pd.merge(consolidated_df3, df, on='datetime', how='outer')\n",
    "\n",
    "# drop all the columns that contains 'percentage'\n",
    "df_components_daily_merge = consolidated_df3.loc[:,~consolidated_df3.columns.str.contains('percentage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrames to CSV\n",
    "df_components_daily_merge.to_csv('../../data/df_components_daily_merge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the consolidated data\n",
    "consolidated_df4 = pd.DataFrame(columns=['values', 'percentage', 'datetime',])\n",
    "for key, df in dfs_components_intradaily.items():\n",
    "    # Renombra las columnas 'values' y 'datetime' para que tengan el nombre del tipo de generación\n",
    "    \n",
    "    # Fusiona el DataFrame actual con el consolidado en función de la columna 'datetime'\n",
    "    consolidated_df4 = pd.merge(consolidated_df4, df, on='datetime', how='outer')\n",
    "\n",
    "# drop all the columns that contains 'percentage'\n",
    "df_components_intradaily_merge = consolidated_df4.loc[:,~consolidated_df4.columns.str.contains('percentage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrames to CSV\n",
    "df_components_intradaily_merge.to_csv('../../data/df_components_intradaily_merge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
